{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffamilies = [\n",
    "    lambda k: lambda x: x[0, 0]**2 + k * x[0, 0] * x[0, 1] + x[0,1]**2,\n",
    "    lambda k: lambda x: k * x[0, 0] + k**2 * x[0, 1],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial(f, x, i=[0], dx=1e-6):\n",
    "    \"\"\"Computes the i-th partial derivative of f at point x.\n",
    "    \n",
    "    Args:\n",
    "        f: objective function.\n",
    "        x: point at which partial derivative is computed.\n",
    "        i: list of coordinates along which derivative is computed (differentiates successively once per coordinate).\n",
    "        dx: slack for finite difference.\n",
    "        \n",
    "    Output:\n",
    "        (float)\n",
    "    \"\"\"\n",
    "    if not i:\n",
    "        return f(x)\n",
    "    x = x.reshape(1, -1)\n",
    "    h = np.zeros(x.shape)\n",
    "    h[0, i[0]] = dx\n",
    "    p1 = partial(f, x + h, i[1:], dx)\n",
    "    p2 = partial(f, x - h, i[1:], dx)\n",
    "    return (p1 - p2) / (2*dx)\n",
    "\n",
    "def deriv1(f, x, i, dx=1e-6):\n",
    "    return partial(f, x, [i], dx)\n",
    "\n",
    "def deriv2(f, x, i, j, dx=1e-6):\n",
    "    return partial(f, x, [i, j], dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(f, x, dx=1e-6):\n",
    "    \"\"\"Computes gradient of f at point x.\n",
    "    \n",
    "    Args:\n",
    "        f: objective function.\n",
    "        x: point at which gradient is computed.\n",
    "        dx: slack for finite difference of partial derivatives.\n",
    "        \n",
    "    Output:\n",
    "        (ndarray) of size domain of f.\n",
    "    \"\"\"\n",
    "    x = x.reshape(1, -1)\n",
    "    dim = x.shape[1]\n",
    "    return np.array([deriv1(f, x, i, dx) for i in range(dim)]).reshape(1, -1)\n",
    "\n",
    "def hessian(f ,x, dx=1e-6):\n",
    "    \"\"\"Computes hessian of f at point x.\n",
    "    \n",
    "    Args:\n",
    "        f: objective function.\n",
    "        x: point at which hessian is computed.\n",
    "        dx: slack for finite difference of partial derivatives.\n",
    "        \n",
    "    Output:\n",
    "        (ndarray) of square shape and size domain of f.\n",
    "    \"\"\"\n",
    "    x = x.reshape(1, -1)\n",
    "    dim = x.shape[1]\n",
    "    line = lambda i: np.array([deriv2(f, x, i, j, dx) for j in range(dim)])\n",
    "    return np.array([line(i) for i in range(dim)])\n",
    "\n",
    "# Nombre de conditionnement : rapport entre la plus grande et la\n",
    "# plus petite des courbures parmi les directions partant de x.\n",
    "def condition_number(f, x):\n",
    "    H = hessian(f, x)\n",
    "    eivals, _ = np.linalg.eig(H)\n",
    "    return abs(max(eivals) / min(eivals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassicUpdater:\n",
    "    def __init__(self, rate=0.01, tol=1e-6):\n",
    "        self.rate = rate if callable(rate) else lambda reset: rate\n",
    "        self.tol = tol\n",
    "\n",
    "    def __call__(self, f, x, reset):\n",
    "        return self.rate(reset) * -gradient(f, x, self.tol)\n",
    "\n",
    "ln_decay = lambda n: lambda tol: lambda f, x: np.linalg.norm(gradient(f, x, tol), ord=n)\n",
    "l1_decay = ln_decay(1)\n",
    "l2_decay = ln_decay(2)\n",
    "\n",
    "class GD():\n",
    "    \"\"\"Gradient Descent Object.\n",
    "    \n",
    "    Implements gradient descent aiming to compute optimal objective \n",
    "    value of convex functions and local optimal ones of none \n",
    "    convex functions.\n",
    "    \"\"\"    \n",
    "    def __init__(self, delta=None, decay=None, tol=1e-6, max_iter=1000):\n",
    "        \"\"\"\n",
    "        Instantiates a GD object.\n",
    "    \n",
    "        Attributes:\n",
    "        delta: function computing descent update vector (direction + step)\n",
    "        decay: function computing decay\n",
    "        tol: slack tolerance.\n",
    "        max_iter: upper bound on number of iterations.\n",
    "        \"\"\"\n",
    "        self.delta = delta if delta is not None else ClassicUpdater(0.01, tol)\n",
    "        self.decay = decay if decay is not None else l2_decay(tol)\n",
    "        self.tol = tol\n",
    "        self.max_iter = max_iter\n",
    "        self.grad = gradient\n",
    "    \n",
    "    def __call__(self, x, f):\n",
    "        \"\"\"Calling gradient descent object with specific starting point and optimal function.\n",
    "        \n",
    "        Args:\n",
    "            x: initial starting point for descent.\n",
    "            f: objective function of optimisation problem.\n",
    "        \n",
    "        Output:\n",
    "            (float) sub-optimal value up to tolerance if execution is proper.\n",
    "            (ndarray) list of gradient descent iterates.\n",
    "        \"\"\"\n",
    "        # Helper functions\n",
    "        compute_delta = lambda x, reset=False: self.delta(f, x, reset)\n",
    "        compute_decay = lambda x: self.decay(f, x)\n",
    "        \n",
    "        # Start\n",
    "        x = x.reshape(1, -1)\n",
    "        n_iter = 0\n",
    "        iters, iters_dir = x, compute_delta(x, reset=True)\n",
    "        decay = compute_decay(x)\n",
    "        while decay > self.tol and n_iter < self.max_iter:\n",
    "            ## Decide on direction\n",
    "            delta = compute_delta(x)\n",
    "            ## Update iterate\n",
    "            x = x + delta\n",
    "            ## Store on-going data\n",
    "            iters = np.vstack([iters, x])\n",
    "            iters_dir = np.vstack([iters_dir, delta])\n",
    "            ## Update decay\n",
    "            decay = compute_decay(x)\n",
    "            ## Update iteration number\n",
    "            n_iter += 1\n",
    "\n",
    "        # Display results\n",
    "        msg = \" Iteration nu. = {}\\n approx. = {}\\n ob value = {}\\n and decay = {}.\"\n",
    "        #print(msg.format(n_iter, x.flatten(), f(x), decay))\n",
    "        if decay > self.tol:\n",
    "            warnings.warn(\"Decay didn't get under tolerance rate.\", RuntimeWarning)\n",
    "        return (x, iters, iters_dir, n_iter) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3dfd8dfd68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_gradient_descent(f, x, k_max):\n",
    "    \"\"\"Plot the number iterations of a constant gradient descent of f at point x with several k,\n",
    "       contrasted with the conditionnement number\n",
    "    \n",
    "    Args:\n",
    "        f: objective function.\n",
    "        x: point at which gradient is computed.\n",
    "        k_max: number of k (0 to k_max)\n",
    "    \"\"\"\n",
    "\n",
    "    DG_classic = GD()\n",
    "\n",
    "    list_iter = [DG_classic(x, f(k))[3] for k in range(k_max)]\n",
    "    list_cond = [condition_number(f(k), x) for k in range(k_max)]\n",
    "\n",
    "    array_cond = np.array(list_cond)\n",
    "    array_iter = np.array(list_iter)\n",
    "\n",
    "    array_tuple = list(zip(array_cond, array_iter))\n",
    "    array_tuple.sort(key=lambda tup: tup[0])\n",
    "\n",
    "    array_cond_iter = list(zip(*array_tuple))\n",
    "\n",
    "    plt.plot(array_cond_iter[0], array_cond_iter[1], label=\"x² + kxy + y²\")\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.xlabel(\"Conditionnement number\")\n",
    "    plt.ylabel(\"Number of iteration\")\n",
    "    plt.title(\"Gradient descent of a same family function with constant steps\")\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "plot_gradient_descent(ffamilies[0], np.array([1, 1]), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Iteration nu. = 736\n",
      " approx. = [3.48651638e-07 3.48651638e-07]\n",
      " ob value = 2.431159291034752e-13\n",
      " and decay = 9.8613574948579e-07.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DG_classic = GD()\n",
    "DG_classic(np.r_[1, 1], ffamilies[0](0))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExponentialLRScheduler:\n",
    "    def __init__(self, initial_rate=0.1, r=0.1):\n",
    "        self.initial_rate = initial_rate\n",
    "        self.r = r\n",
    "\n",
    "    def __call__(self, reset):\n",
    "        if reset:\n",
    "            self.n_iter = 0\n",
    "        return self.initial_rate * 10**(- self.n_iter / self.r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'ExponentialLRScheduler' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-47c85ae10a7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mDG_classic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mClassicUpdater\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mExponentialLRScheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mDG_classic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mffamilies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-9320327b15dd>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, f)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0miters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miters_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_delta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mdecay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_decay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mdecay\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-9320327b15dd>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x, reset)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \"\"\"\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# Helper functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mcompute_delta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mcompute_decay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-9320327b15dd>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, f, x, reset)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mln_decay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'ExponentialLRScheduler' and 'float'"
     ]
    }
   ],
   "source": [
    "DG_classic = GD(ClassicUpdater(ExponentialLRScheduler()))\n",
    "DG_classic(np.r_[15, 20], ffamilies[0](0))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NesterovUpdater:\n",
    "    def __init__(self, rate=0.01, momentum=0.9, tol=1e-6):\n",
    "        self.rate = rate\n",
    "        self.momentum = momentum\n",
    "        self.tol = tol\n",
    "    \n",
    "    def __call__(self, f, x, reset):\n",
    "        x = x.reshape(1, -1)\n",
    "        if reset is True:\n",
    "            self.m_vect = np.zeros(x.shape[1])\n",
    "        mv = self.momentum * self.m_vect\n",
    "        self.m_vect = mv - self.rate * gradient(f, x + mv, self.tol)\n",
    "        return self.m_vect\n",
    "    \n",
    "class RMSProp:\n",
    "    def __init__(self, rate=0.01, beta=)\n",
    "\n",
    "class AdamUpdater:\n",
    "    def __init__(self, rate=0.01, beta1=0.9, beta2=0.9, tol=1e-6, epsilon=1e-7):\n",
    "        self.rate = rate\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.tol = tol\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def __call__(self, f, x, reset):\n",
    "        x = x.reshape(1, -1)\n",
    "        if reset is True:\n",
    "            self.n_iter = 1\n",
    "            self.m_vect = np.zeros(x.shape[1])\n",
    "            self.s_vect = np.zeros(x.shape[1])\n",
    "        gf = gradient(f, x, self.tol)\n",
    "        m = self.beta1 * self.m_vect - (1 - self.beta1) * gf\n",
    "        s = self.beta2 * self.s_vect + (1 - self.beta2) * gf * gf\n",
    "        self.m_vect = m / (1 - self.beta1**self.n_iter)\n",
    "        self.s_vect = s / (1 - self.beta2**self.n_iter)\n",
    "        return self.rate * self.m_vect / np.sqrt(self.s_vect + self.epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Iteration nu. = 252\n",
      " approx. = [3.17311626e-08 4.23082156e-08]\n",
      " ob value = 2.7968517893163512e-15\n",
      " and decay = 1.0577054011994732e-07.\n",
      "\n",
      " Iteration nu. = 26\n",
      " approx. = [-4.04407778e+10 -4.04408040e+10]\n",
      " ob value = 3.2709151367261187e+21\n",
      " and decay = 0.0.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DG_nesterov = GD(NesterovUpdater())\n",
    "DG_nesterov(np.r_[15, 20], ffamilies[0](0))\n",
    "print()\n",
    "DG_adam = GD(AdamUpdater())\n",
    "DG_adam(np.r_[15, 20], ffamilies[0](0))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
